// OLLAMA DIAGNOSTIC TOOL - Comprehensive Ollama testing
console.log('ğŸ”§ LOADING OLLAMA DIAGNOSTIC...');

window.diagnoseOllama = async function() {
    console.log('ğŸ” STARTING OLLAMA DIAGNOSTIC');
    console.log('='.repeat(60));
    
    const results = {
        tagsEndpoint: false,
        generateEndpoint: false,
        modelLoaded: false,
        errors: []
    };
    
    try {
        // Test 1: Tags Endpoint
        console.log('ğŸ“¡ Test 1: Testing /api/tags endpoint...');
        try {
            const tagsResponse = await fetch('http://localhost:11434/api/tags');
            console.log('ğŸ“Š Tags response status:', tagsResponse.status);
            console.log('ğŸ“Š Tags response headers:', Object.fromEntries(tagsResponse.headers));
            
            if (!tagsResponse.ok) {
                throw new Error(`HTTP ${tagsResponse.status}: ${tagsResponse.statusText}`);
            }
            
            const tagsData = await tagsResponse.json();
            console.log('âœ… Tags endpoint working!');
            console.log('ğŸ“‹ Available models:', tagsData.models.map(m => `${m.name} (${Math.round(m.size/1024/1024)}MB)`));
            
            results.tagsEndpoint = true;
            results.models = tagsData.models;
            
            // Check if llama3.2 is available
            const llama32 = tagsData.models.find(m => m.name.includes('llama3.2'));
            if (llama32) {
                console.log('âœ… llama3.2 model found!');
                results.modelLoaded = true;
            } else {
                console.log('âš ï¸ llama3.2 model not found. Available models:', tagsData.models.map(m => m.name));
                results.errors.push('llama3.2 model not found');
            }
            
        } catch (error) {
            console.error('âŒ Tags endpoint failed:', error);
            results.errors.push(`Tags endpoint: ${error.message}`);
        }
        
        // Test 2: Generate Endpoint
        console.log('\nğŸ“¡ Test 2: Testing /api/generate endpoint...');
        try {
            const generatePayload = {
                model: 'llama3.2',
                prompt: 'Hello, respond with just "OK"',
                stream: false,
                options: {
                    temperature: 0.1,
                    top_p: 0.9,
                    max_tokens: 10
                }
            };
            
            console.log('ğŸ“¤ Sending payload:', JSON.stringify(generatePayload, null, 2));
            
            const generateResponse = await fetch('http://localhost:11434/api/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(generatePayload)
            });
            
            console.log('ğŸ“Š Generate response status:', generateResponse.status);
            console.log('ğŸ“Š Generate response headers:', Object.fromEntries(generateResponse.headers));
            
            if (!generateResponse.ok) {
                const errorText = await generateResponse.text();
                console.error('âŒ Generate endpoint error:', errorText);
                throw new Error(`HTTP ${generateResponse.status}: ${errorText}`);
            }
            
            const generateData = await generateResponse.json();
            console.log('âœ… Generate endpoint working!');
            console.log('ğŸ“ Response:', generateData);
            console.log('ğŸ“ Response text:', generateData.response);
            console.log('ğŸ“Š Response length:', generateData.response?.length || 0);
            
            results.generateEndpoint = true;
            results.generateResponse = generateData;
            
        } catch (error) {
            console.error('âŒ Generate endpoint failed:', error);
            results.errors.push(`Generate endpoint: ${error.message}`);
        }
        
        // Test 3: Model Info
        console.log('\nğŸ“¡ Test 3: Testing model info...');
        try {
            const modelResponse = await fetch('http://localhost:11434/api/show', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    name: 'llama3.2'
                })
            });
            
            if (modelResponse.ok) {
                const modelData = await modelResponse.json();
                console.log('âœ… Model info retrieved!');
                console.log('ğŸ“Š Model details:', {
                    name: modelData.model,
                    modified: modelData.modified_at,
                    size: modelData.size ? Math.round(modelData.size/1024/1024) + 'MB' : 'Unknown'
                });
                results.modelInfo = modelData;
            } else {
                console.log('âš ï¸ Model info endpoint failed, but this is not critical');
            }
        } catch (error) {
            console.log('âš ï¸ Model info test failed (not critical):', error.message);
        }
        
    } catch (error) {
        console.error('âŒ Diagnostic failed:', error);
        results.errors.push(`General: ${error.message}`);
    }
    
    // Generate report
    console.log('\nğŸ“Š DIAGNOSTIC REPORT');
    console.log('='.repeat(60));
    console.log('âœ… Tags Endpoint:', results.tagsEndpoint);
    console.log('âœ… Generate Endpoint:', results.generateEndpoint);
    console.log('âœ… Model Loaded:', results.modelLoaded);
    
    if (results.errors.length > 0) {
        console.log('\nâŒ ERRORS:');
        results.errors.forEach((error, index) => {
            console.log(`${index + 1}. ${error}`);
        });
    }
    
    // Provide recommendations
    console.log('\nğŸ”§ RECOMMENDATIONS:');
    if (!results.tagsEndpoint) {
        console.log('âŒ Ollama is not running or not accessible');
        console.log('   Solution: Run "ollama serve" in PowerShell');
    } else if (!results.modelLoaded) {
        console.log('âš ï¸ llama3.2 model not found');
        console.log('   Solution: Run "ollama pull llama3.2" or "ollama run llama3.2"');
    } else if (!results.generateEndpoint) {
        console.log('âŒ Generate endpoint not working');
        console.log('   Solution: Restart Ollama with "ollama serve"');
        console.log('   Check Ollama logs for errors');
    } else {
        console.log('âœ… Everything is working correctly!');
        console.log('   The test prompt should now work');
    }
    
    // Show results in UI
    let output = `ğŸ” OLLAMA DIAGNOSTIC REPORT\n`;
    output += `========================\n\n`;
    output += `âœ… Tags Endpoint: ${results.tagsEndpoint ? 'WORKING' : 'FAILED'}\n`;
    output += `âœ… Generate Endpoint: ${results.generateEndpoint ? 'WORKING' : 'FAILED'}\n`;
    output += `âœ… Model Loaded: ${results.modelLoaded ? 'FOUND' : 'NOT FOUND'}\n\n`;
    
    if (results.models && results.models.length > 0) {
        output += `ğŸ“‹ Available Models:\n`;
        results.models.forEach(model => {
            output += `  â€¢ ${model.name} (${Math.round(model.size/1024/1024)}MB)\n`;
        });
        output += `\n`;
    }
    
    if (results.errors.length > 0) {
        output += `âŒ Errors Found:\n`;
        results.errors.forEach((error, index) => {
            output += `  ${index + 1}. ${error}\n`;
        });
        output += `\n`;
    }
    
    output += `ğŸ”§ Recommendations:\n`;
    if (!results.tagsEndpoint) {
        output += `  â€¢ Run: ollama serve\n`;
        output += `  â€¢ Check if Ollama is running\n`;
    } else if (!results.modelLoaded) {
        output += `  â€¢ Run: ollama pull llama3.2\n`;
        output += `  â€¢ Or: ollama run llama3.2\n`;
    } else if (!results.generateEndpoint) {
        output += `  â€¢ Restart Ollama: ollama serve\n`;
        output += `  â€¢ Check Ollama logs\n`;
    } else {
        output += `  â€¢ Everything is working!\n`;
        output += `  â€¢ Try the test prompt again\n`;
    }
    
    // Display in test results
    const resultsDiv = document.getElementById('testResults');
    const outputDiv = document.getElementById('testOutput');
    
    if (resultsDiv && outputDiv) {
        resultsDiv.style.display = 'block';
        outputDiv.textContent = output;
        
        // Add color coding
        outputDiv.innerHTML = output
            .replace(/âœ…/g, '<span class="success">âœ…</span>')
            .replace(/âŒ/g, '<span class="error">âŒ</span>')
            .replace(/âš ï¸/g, '<span class="warning">âš ï¸</span>')
            .replace(/ğŸ”§/g, '<span class="info">ğŸ”§</span>')
            .replace(/ğŸ“‹/g, '<span class="info">ğŸ“‹</span>');
    }
    
    console.log('\nğŸ¯ DIAGNOSTIC COMPLETE!');
    return results;
};

// Add manual test functions
window.testOllamaManual = async function() {
    console.log('ğŸ§ª MANUAL OLLAMA TEST');
    
    try {
        // Test tags
        console.log('Testing tags...');
        const tagsResponse = await fetch('http://localhost:11434/api/tags');
        const tagsData = await tagsResponse.json();
        console.log('Tags OK:', tagsData.models.length, 'models');
        
        // Test generate
        console.log('Testing generate...');
        const generateResponse = await fetch('http://localhost:11434/api/generate', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                model: 'llama3.2',
                prompt: 'Say "Hello World"',
                stream: false
            })
        });
        const generateData = await generateResponse.json();
        console.log('Generate OK:', generateData.response);
        
        alert('âœ… Manual test successful! Check console for details.');
        
    } catch (error) {
        console.error('Manual test failed:', error);
        alert(`âŒ Manual test failed: ${error.message}`);
    }
};

console.log('ğŸ”§ Ollama diagnostic loaded. Available commands:');
console.log('  diagnoseOllama() - Full diagnostic');
console.log('  testOllamaManual() - Quick manual test');
